---
layout: post
title: "New: Child sex abuse victim begs Elon Musk to remove links to her images"
date: 2025-08-25T23:17:45
author: "badely"
categories: [Technology]
tags: []
excerpt: "BBC investigation finds US victim's images are traded globally by an operator based in Indonesia."
image: assets/images/43d2222153bc6951bf83dc788f0164a0.jpg
---

According to new developments, A victim of child sexual abuse has begged Elon Musk to stop links offering images of her abuse being posted on his social media platform X.

"Hearing that my abuse - and the abuse of so many others - is still being circulated and commodified here is infuriating," says "Zora" (not her real name) who lives in the United States and was first abused more than 20 years ago.

"Every time someone sells or shares child abuse material, they directly fuel the original, horrific abuse."

X says it has "zero tolerance for child sexual abuse material" and tackling those who exploit children remains "a top priority".

The BBC found images of Zora while investigating the global trade of child sex abuse material, estimated to be worth billions of dollars by Childlight, the Global Child Safety Institute.

The material was among a cache of thousands of similar photos and videos being offered for sale on an X account. We got in contact with the trader through the messaging app Telegram, and this led us to a bank account linked to a person in Jakarta, Indonesia.

Zora was first abused by a family member. A collection of images of her abuse have become infamous among paedophiles who collect and trade such content.  Many other victims face the same situation, as images of abuse continue to circulate today.

Zora is angered the trade continues to this day.

"My body is not a commodity. It never has been, and it never will be," she says.

"Those who distribute this material are not passive bystanders, they are complicit perpetrators."

Images of Zora's abuse were originally only available on the so-called dark web, but she now has to live with the reality that links are being openly promoted on X.

Social media platforms are trying to rid their platforms of illegal material, but the scale of the problem is enormous. 

Last year the US National Center for Missing and Exploited Children (NCMEC), received more than 20 million mandatory reports from tech companies about incidents of child sexual abuse material (CSAM) - illegal images and videos on their platforms. 

NCMEC attempts to identify victims and perpetrators, the organisation then contacts law enforcement.

We approached "hacktivist" group Anonymous, whose members are trying to combat the trade in child abuse images on X. One of them told us the situation was as bad as ever.

They tipped us off about a single account on X. It used a photo of the head and shoulders of a real child as its avatar. There was nothing obscene about it.

But the words and emojis in the account's bio made it clear the owner was selling child sexual abuse material and there was a link to an account on the messaging app Telegram.

The trader appeared to be based in Indonesia and was offering "VIP packages", collections of images and video files of abuse for sale to paedophiles around the world.

The Anonymous activist had been working to report this trader's multiple accounts on X, so they could be removed by the platform's moderation systems. But each time one account was removed, he told us, another new one would replace it.

The trader appeared to have been overseeing more than 100 almost-identical accounts. The activist told us that when he had contacted the trader directly using Telegram, the trader had replied saying he had thousands of videos and images for sale.

"I have baby. Kids young 7-12", he wrote in messages to the activist seen by the BBC. He also explained that some of the content showed child rape.

We got in touch with the trader ourselves. 

He provided links to samples of material, which we did not open or view. Instead, we contacted experts from the Canadian Centre for Child Protection (CCCP) in Winnipeg - who work alongside law enforcement and are legally permitted to view such content.

"The Telegram account was, for lack of a better term, a taster pack - essentially a collage of the material he had available of all the different victims," explained Lloyd Richardson, the CCCP's director of technology. "When we looked at all the different images in the collages, I would say there were thousands."

Among the files were images of Zora.

Her abuser in the US was prosecuted and imprisoned many years ago, but not before footage of the abuse had already been shared and sold across the world.

Zora told us: "I have tried over the years to overcome my past and not let it determine my future, but perpetrators and stalkers still find a way to view this filth."

As she grew older, stalkers uncovered Zora's identity, contacting and threatening her online. She says she feels "bullied over a crime that robbed me of my childhood".

To identify the trader selling photos of Zora, we posed as a buyer.

The trader sent us his bank information and an online payment account, both had the same name listed as the account holder.

The Anonymous activist had discovered this name was also linked to two money transfers and another bank account.

We tracked down a man with the same name as that listed on the accounts, to an address on the outskirts of the Indonesian capital, Jakarta.

A producer working in the city for the BBC World Service went to visit the address and confronted a man on the premises who, when presented with the evidence, said he was shocked.

"I don't know anything about this," he said.

The man confirmed one of the bank accounts was his and stated it was created for a single mortgage-related transaction. He said he had not used the account since and that he would contact his bank to find out what had happened. He denied knowledge of the other bank account or the money transfers.

We cannot know for certain if, and to what extent, he may be involved and as a result we are not naming him.

The way Zora's images were being marketed is a method used by hundreds of traders across the world, our investigation found.

Posts on X use different hashtags familiar to paedophiles. Images that appear on the platform are often taken from known child abuse images but can be cropped so they are not obscene.

Elon Musk said removing child sexual abuse material was his "top priority" when he took over X, then known as Twitter, in 2022.

Social media platforms in general, not just X, could do much more to prevent criminals posting repeatedly in this way, says Lloyd Richardson from the CCCP.

"It's great that we can send a takedown notice [to social media platforms], and they remove the account, but that's the bare minimum."

The problem is that users can come back onto the platforms in a few days with a new account, he says.

X told us it has "zero tolerance" for child sexual exploitation. "We continually invest in advanced detection to enable us to take swift action against content and accounts that violate our rules," said a spokesperson.

The platform told us it works "closely with the National Center for Missing and Exploited Children (NCMEC) and supports law enforcement efforts to prosecute these heinous crimes".

Telegram said: "All channels are moderated, and more than 565,000 groups and channels related to the spread of CSAM have been banned so far in 2025."

The platform said it has more than a thousand moderators working on the issue.

"Telegram proactively monitors public content across the platform and removes objectionable material before it can reach users or be reported," a spokesperson said.

When we told Zora her photos were being traded using X, she had this message for the platform's owner, Elon Musk: "Our abuse is being shared, traded, and sold on the app you own. If you would act without hesitation to protect your own children, I beg you to do the same for the rest of us. The time to act is now."

If you are affected by any of the issues raised in this report, help and support is available via the BBC Action Line

