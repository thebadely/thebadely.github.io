---
layout: post
title: "Big News: The real reason weather forecasters (like me) often appear to get it wrong"
date: 2025-08-05T23:05:58
author: "badely"
categories: [News]
tags: []
excerpt: "The accuracy of forecasting has improved enormously - and AI promises further advances. But there are certain challenges in finding ways to share that"
image: assets/images/cca4a132e1f8886cf2aca404d481cc54.jpg
---

Let's dive into the details: Sometimes I'll be walking around a supermarket, and a shopper will approach me in the aisle. "I hosted a barbecue on Saturday and you told me it was going to rain," they will say. "And it didn't. Why did you get it wrong?".

Or the opposite: they planned for a day of sunshine, only to be disappointed by grey skies. Or a parent might ask me in March what the weather might be like for their son's wedding - in September.

Those people are always delightfully friendly, and the conversations are part of what makes presenting the weather - which I've been doing for the last three decades - such a joy.

But they also shed light on a strange fact.

Over my career, forecasting has improved almost beyond recognition. We can now predict the weather with much higher accuracy, and in more granular detail, than when I began presenting in the mid 1990s.

Liz Bentley, a professor of meteorology at Reading University and chief executive of the Royal Meteorological Society, says that a one-day forecast is correct over 90% of the time. 

But despite those strides, there are still gaps in public trust. 

When YouGov asked British adults last summer whether they trusted the weather forecast, a substantial minority - 37% - said they didn't trust it "very much" or "at all." (Reassuringly, 61% said they did trust forecasters like me.)

Jokes about the forecast are widespread. The 2012 Olympics opening ceremony included a clip of the moment from 1987, when the weather forecaster Michael Fish told viewers not to worry because there wouldn't be a hurricane - only for a storm to hit hours later.

(As it happens, Michael was correct: hurricane-strength winds did strike southeast England that night, but it wasn't technically a hurricane.) Still, the incident became a byword for forecaster error.

So why, with our wealth of knowledge and our powerful forecasting technology, do some people still perceive the weather as incorrect? And do we really get it wrong or is something more complicated at play around how we share forecasts?

Part of the challenge is around expectations, which have risen in our world of round-the-clock access to information.

We can tweak the temperature of our fridge or identify a problem in our car from our smartphones in a fraction of a second. So why can't we find out whether it's going to rain on our street at 2pm on Sunday with 100% accuracy - surely, an easier feat? 

Another part of the challenge is how that wealth of information is boiled down and communicated.

Meteorology produces an overwhelming amount of data; it's difficult to condense it into a snappy, TV or digital app-friendly prediction. It means that even when we are technically correct, some viewers might still end up confused.

But the answer also lies in the tricky nature of meteorology. 

It's a delicate science, and any tiny inaccuracy in the data can skew things - or knock it out of shape.

Every day, across the British Isles, forecasters collect "observations" (or data) on things like temperature and wind speed, through a network of more than 200 "weather stations" run by the Met Office. The data is then plugged into mathematical models run by powerful machines, or "supercomputers". 

Earlier this year the Met Office unveiled a new supercomputer, switching for the first time from a physical machine to cloud-based software.

The new device will deliver "better forecasts and help scientists advance important climate research around the world", the Met Office says.

But as with any science, there are weaknesses.

The atmosphere is known as a "chaotic system", meaning that a slight error - even as small as 0.01C - in the initial observations can produce a drastically different result.

"It's called Chaos Theory," explains Prof Bentley. "Or the Butterfly Effect. The analogy is that if a butterfly flaps its wings in Brazil, it could have an impact on the atmosphere across northern Europe, six days later."

There's also a particular challenge when predicting the weather over small geographic areas.

In the 1990s, a weather event needed to be larger than about 100 miles (161km) before it could be fully observed - now, the UK-wide weather model used by the Met Office can map weather events as small as 2 miles (3km), Prof Bentley says. 

But zooming in beyond that size remains difficult, so predicting weather like heavy fog - which might affect only a 1km space - is particularly tricky.

And even with huge improvements in the science, technology glitches still happen - though these are mercifully rare. 

Last autumn, the BBC Weather website briefly showed impossibly fast winds of over 13,000mph in London, as well as temperatures of 404C in Nottingham. 

The BBC apologised for "an issue with some of the weather data from our forecast provider".

The biggest challenge of my job is synthesising this data so it fits into a tight television segment. 

"There's no other science as tested, checked and judged by the general public," says Scott Hosking, a director of environmental forecasting at the Alan Turing Institute.

"It's as complex as nuclear fusion physics, but most of us don't experience that day to day, and so we don't have to come up with a way to communicate that science to the public."

It's also easy to forget that forecasting is just that - predicting.

Over the years, we've gotten a lot better at this subtle art of "communicating uncertainty". Meteorologists now produce "ensemble forecasts", where they might run 50 different models, all with slight variations. 

If all of those scenarios point to a similar outcome, meteorologists can be confident they've got it right. If they produce different outcomes, then their confidence is much lower.

This is why, on a weather app, you might see a 10% chance of rain in your area.

Forecasters often think about this tricky issue of communication; how the weather can be more easily explained.

Last week, the BBC announced a new partnership with the Met Office. It came eight years after they officially ended their relationship (since 2018, the Dutch MeteoGroup has provided the BBC's forecasts). 

The new deal aims to combine expertise of the two organisations and "turn science into stories," explained Tim Davie, the BBC's director-general.

Certainly, some think more creativity is needed in communicating the weather. Dr Hosking of the Alan Turing Institute suggests forecasters could move away from giving a percentage chance of rain, and instead use the "storyline approach". 

In this style, forecasters could say things like, "What we're seeing now is similar to what we saw at a certain event a few years ago' - something within memory."

This is partly why the Met Office, in 2015, decided to name storms.

But Prof Bentley argues that numbers can be powerful - and perhaps it's better to arm consumers with the hard data they need.

In the US, she says, the weather forecast has percentages "everywhere"; American consumers are told of everything from chance of rain, to the likely spread in temperature.

"The public are comfortable [with it]," she says. "Because they've had that information given to them so often, they kind of get it."

Weather forecasting could soon change dramatically with the advent of Artificial Intelligence (AI). The use of machine learning to predict the weather has developed rapidly in recent months.

It's often said that forecasters have gained 24 hours of accuracy with each passing decade, meaning the Met Office can now release a weather warning seven days in advance.

But AI models designed by Google DeepMind are already correctly predicting the weather 15 days in advance, Dr Hosking says.

Earlier this year, a team of researchers at Cambridge University released a fully AI-driven weather programme called Aardvark Weather. The results were written in the Nature journal.

Whilst traditional forecasting requires hours of use on a powerful supercomputer, researchers say, Aardvark can be deployed on a desktop computer in minutes. They claim this uses "thousands of times" less computing power, and that it can predict the weather in more granular detail. 

They also claim it will improve forecasts in west Africa and other poor regions (the best traditional forecasting models are mostly designed for Europe and the United States).

"It could be transformational; it's super exciting," says Richard Turner, professor of machine learning at Cambridge University, who is one of the designers of the model.

But Prof Bentley identifies a weakness in AI-driven weather models: they are fed with reams of historic data, and trained to spot patterns - which in her view makes it very difficult to predict events that haven't happened yet.

"With climate change, we're going to see new records," she says. "We may see 41C in the UK. But if AI is always looking backwards, it will never see 41 because we've not had it yet."

Prof Turner accepts that this is a challenge with AI models like his and says his team is working on remedies.

In the future, analysts think, forecasts will go into more depth. Rather than just predicting rain, the forecast will increasingly tell you what effect that rain will have - on your travel, or on your garden plans.

Prof Bentley calls this the "so what" factor. "Do you put something on [a weather app] that says, 'If you're planning a barbecue, then you might want to do it at lunchtime because the chances are you're going to get washed out in the afternoon'?"

This chimes with a trend I've noticed from my own career: a growing interest in understanding the science behind the weather. 

Viewers are no longer just interested in knowing whether there'll be a heatwave; they want to know why.

That's the reason we publish more content explaining the physics of the aurora borealis, or why climate change is leading to bigger hailstones.

As for AI, it certainly could improve accuracy - but there's a risk, also, that viewers become deluged by information. Dr Hosking says that because AI is more nimble and can tweak weather models more quickly, users will soon have access to frequently-changing forecasts. They may also have "much more localised" information, he says (perhaps giving data not just on your town, but on your back garden, other analysts predict).

This could lead to an overwhelming amount of data for those using the app, gluing users to their smartphones. And in that world, it will become even more important for human forecasters to communicate the weather in a clear, understandable way.

But there are upsides too - not least the prospect of much longer-term, more accurate forecasts. 

Perhaps one day, when a mother asks me to predict weather at her son's wedding six months from now, I might be able to give a slightly better answer.

Additional reporting: Luke Mintz

BBC InDepth is the home on the website and app for the best analysis, with fresh perspectives that challenge assumptions and deep reporting on the biggest issues of the day. And we showcase thought-provoking content from across BBC Sounds and iPlayer too. You can send us your feedback on the InDepth section by clicking on the button below.

