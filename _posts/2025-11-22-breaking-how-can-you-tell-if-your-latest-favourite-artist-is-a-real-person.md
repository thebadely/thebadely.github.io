---
layout: post
title: "Breaking: How can you tell if your latest favourite artist is a real person?"
date: 2025-11-22T01:07:20
author: "badely"
categories: [News]
tags: []
excerpt: "As AI-generated music floods streaming platforms, questions bubble over whether listeners are owed more transparency."
image: assets/images/fd28dd058b41254cc9750cd61edb955a.jpg
---

Let's dive into the details: There's a new song doing the rounds, and in the immortal words of Kylie Minogue, you just can't get it out of your head.

But what if it was created by a robot, or the artist themself is a product of artificial intelligence (AI)? Do streaming sites have an obligation to label music as AI-generated? And does it even matter, if you like what you hear?

A survey published last week suggested 97% of respondents could not spot an AI-generated song. But there are some telltale signs - if you know where to look. 

Here's a quick guide. 

AI music became one of last summer's hottest topics after accusations the band The Velvet Sundown was AI-generated sent them viral.

The band, who had no record label and a minimal social media footprint, quickly racked up hundreds of thousands of monthly listeners on Spotify after releasing two albums just weeks apart - and the music world grew suspicious.

The band initially denied the claims, later describing themselves as a synthetic project "guided by human creative direction, and composed, voiced and visualised with the support of artificial intelligence".

They claimed the project was an "artistic provocation", not a trick, but many fans felt betrayed.

Internet sleuths were suspicious of the band's airbrushed photos, which featured non-descript backgrounds and a warm orange filter.

There was also no record of them having performed live – no glowing reviews from fans posted online, nor any concert photos or videos. The band members had not given interviews and did not appear to have individual social media accounts.

Looking into the real-life and social media presence of an artist can be one helpful indicator of whether or not they are real. But experts tell the BBC that fast-developing, sophisticated technology means it is increasingly hard to know when a song has been made using AI.

Still, while it may be tricky, they say there are signs listeners can be alert to.

When LJ Rich started creating AI music around five years ago, she recalls how it could only generate three seconds at a time, taking about 10 hours to create a minute of audio.

Now, an entire song can be summoned rapidly with a single prompt, sparking what industry experts have described as an "explosion" of AI music, sometimes referred to as "slop" - on streaming platforms.

A song with a formulaic feel - sweet but without much substance or emotional weight - can be a sign of AI, says the musician and technology speaker, as well as vocals that feel breathless.

AI songs tend to stick to generic verse-chorus structures, and usually don't have a satisfying ending. AI is also more likely to create lyrics that follow a correct grammatical structure, says Rich, whereas some of the most beautiful or memorable words penned by humans don't always make sense. 

Just ask Alicia Keys and her "concrete jungle where dreams are made of", or The Rolling Stones and their flirtation with double negatives in (I Can't Get No) Satisfaction.

"If it doesn't feel emotional, it's a really big part," the former BBC Click presenter continues. "Does it create that tension and resolution that is a fundamental part of the music that we love? Does it have a story inside it?"

Another tell-tale sign is unrealistic levels of productivity. Professor Gina Neff, from the Minderoo Centre for Technology and Democracy at the University of Cambridge, describes how one artist was recently believed to be AI after dropping multiple soundalike albums simultaneously.

Their songs resembled a mashup of 80s rock bands – like "really classic rock hits that had been put in a blender".

"This will be fine for background music for most people," she continues, "but it won't work for creating the superstars of the future who, of course, draw on the past but then make something completely new out of it."

Sometimes, what might stand out is a song that sounds almost too perfect, lacking minor flaws and variances.

This could mean no strain in the vocals, and overly polished production, according to Tony Rigg, music industry advisor and lecturer in music industry management at the University of Lancashire.

He adds that odd phrasing, unnatural emotional delivery, and lyrics that feel generic or repetitive can also be clues.

"AI hasn't felt heartbreak yet... It knows patterns," he explains. "What makes music human is not just sound but the stories behind it."

It's also worth paying close attention to the vocals. AI "singers" often sound a little slurred. Consonants and plosives (hard sounds like "p" and "t") aren't quite right. You might hear "ghost" harmonies, where backing vocals appear and disappear at random.

However, Rigg calls these signs "hints not proof", acknowledging it is not very easy for the casual listener to detect AI-generated songs.

As well as being used to generate full songs, AI is also becoming a tool some established artists are using to support their creativity.

There currently isn't any obligation – or consistent way – for artists to let fans know if and how they are using AI.

Some are very open: the Beatles, for example, used machine learning to extract the voice of John Lennon from a 1970s cassette recording to release what they called their "last song", Now and Then, in 2023.

And artists including Imogen Heap and Timbaland have created AI personas and released singles under their names.

Last month, Heap released the song Aftercare with her AI model ai.Mogen, trained on her voice.

She created the voice model as a chatbot - a "desperate attempt" to keep up with a deluge of messages and requests including from fans - but more recently, it has featured on several songs and allowed Heap to take part in more collaborations than she otherwise would have due to time constraints.

While "it does sound different if you really know my voice", she says she has put a lot of work into making the AI version of her voice sound human and doesn't think listeners would be able to tell.

Heap isn't trying to mislead listeners –  ai.Mogen is listed as a co-contributor on the track.

But she hopes if people feel a human connection to the song, without already knowing part of the vocals are sung by her AI model, they might reconsider any preconceived negative ideas or fears they have about AI.

"I hope that people listen, don't realise, find peace in that," she tells the BBC.

She says she isn't against using AI to actually create music, but it's just not something she's got around to doing yet.

Heap believes there should be more transparency around what goes into a song, and how AI has been used. 

Citing the example of someone reading the label of a microwave ready meal so they know the ingredients, she says: "We need that for music, and we need that for AI."

There is currently no legal obligation for streaming platforms to label AI-generated songs, despite increasing calls for them to signpost such tracks.

In January, the streaming platform Deezer launched an AI detection tool, followed this summer by a system which tags AI-generated music. 

Deezer says its detection system can flag tracks made with the most prolific AI music creation tools, and is working on expanding its ability to detect music made by others. It says the risk of false positives - eg incorrectly flagging a track created by a human - is very low.

This week, the company said a third (34%) of content uploaded to its platform was fully AI-generated – about 50,000 tracks a day.

Manuel Moussallam, Deezer's director of research, says his team was so surprised by how many tracks were flagged up by the detector when it first launched they were "pretty convinced we had an issue".

The tool quickly flagged up the music by The Velvet Sundown – the band who went viral over the summer – as being "100% AI-generated". 

Other platforms have recently announced steps toward more transparency.

In September, Spotify said it would roll out a new spam filter later this year to identify "bad actors", and prevent "slop" being recommended to listeners. In the past year, it has removed more than 75 million spam tracks.

It is also supporting a way to enable artists to say where and how AI was used in a track, through a system by a consortium of industry members called DDEX. This information will be included in the metadata of a track and displayed on its app.

Spotify says it is about recognising listeners' desire for more information, as well as "strengthening trust".

"It's not about punishing artists who use AI responsibly or down-ranking tracks for disclosing information about how they were made."

If you've fallen hard for a new artist, does it matter if they or their songs are made by AI?

Some believe the presence of AI is irrelevant – engagement is driven by enjoyment, and music people love is already serving its primary purpose.

Others say music fans should be able to make informed choices about what they listen to.

Artists have shared deep concerns around the impact of AI, and hundreds of musicians including Dua Lipa and Sir Elton John have protested about the use of their songs in the training of AI tools.

For LJ Rich, the use of AI in music raises many "weird and beautiful ethical questions" which remain as yet unanswered.

"Like if the music makes the hairs on the back of your neck go up, does it matter if an AI wrote it or not?"

