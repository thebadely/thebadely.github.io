---
layout: post
title: "Big News: Racism, rape and death threats - One weekend of abuse in football"
date: 2025-12-03T06:22:31
author: "badely"
categories: [Sports]
tags: []
excerpt: "More than 2,000 extremely abusive social media posts were sent about managers and players in the Premier League and Women's Super League in a single w"
image: assets/images/9b3ed46f29a66e6ab3e2a6dbf0747c02.jpg
---

Hereâ€™s what you need to know: Managers are being targeted by abuse more often than players in the Premier League and Women's Super League

Warning: This article contains screenshots of and references to offensive language.

More than 2,000 extremely abusive social media posts - including death and rape threats - were sent about managers and players in the Premier League and Women's Super League in a single weekend, a BBC investigation has found.

The analysis - conducted with data science company Signify - focused on posts made during 10 Premier League and six WSL matches on the weekend of 8 and 9 November, and also found messages including racist slurs, homophobia and threats of violence.

Managers were targeted more than players, with 82% of abusive posts made on X, formerly known as Twitter.

Premier League bosses Ruben Amorim, Arne Slot and Eddie Howe were the most common targets of abuse in the men's top flight, while Chelsea and their manager Sonia Bompastor faced 50% of all abuse in the WSL.

A total of 61% of all abusive messages were sent from accounts in the UK and the Republic of Ireland, and the data suggests the overall number is on the rise.

This video can not be played

'It's not acceptable' - Bompastor on online abuse

"Abuse is never a good thing, whether it's about me or other managers," Liverpool head coach Slot said.

"We expect to be criticised. That is completely normal. I do not have social media so I don't see it, but I'm not stupid, I know it's there."

Signify operates an artificial intelligence system called Threat Matrix, which scans posts made on social media for abuse. 

During the weekend of matches selected for the study, it analysed more than 500,000 posts on X, Instagram, Facebook, and TikTok, and identified 22,389 potentially abusive messages.

But those flags can sometimes include examples which aren't abusive. For example, references to Newcastle defender Dan Burn can be flagged as a threat because of his surname.

Therefore, a two-stage analysis by humans is conducted, which found that 2,015 of the posts met the threshold for verified extreme abuse - such as threats to life or hate speech - and broke the rules of the platforms they were posted on.

1 of 7

Thirty-nine posts - including monkey emojis on black players' accounts and rape threats - were deemed serious enough to warrant further investigation, which in some cases involves reporting to football clubs for potential identification of fans, and possible referral to law enforcement.

One post was reported to police, who decided it did not meet their threshold for further action.

Only one of the posts flagged to Meta, which owns and operates Facebook and Instagram, was removed. The others remain under investigation.

Some of those flagged to X were removed, while the others had their reach suppressed but were left online.

"If this happened on the street, this would have criminal consequences, potential financially damaging consequences," said Professional Footballers' Association chief executive Maheta Molango.

"So why is it that online people have got this sense of impunity? We need to put an end to this."

Some in the game are resigned to the inevitability of abuse.

"It comes with the territory now," Newcastle manager Howe said.

"My advice is always to try and shelter yourself from it and become psychologically strong enough to not need to read it. But, invariably, people will show it to you even if you don't want to see it."

Meta has implemented systems for helping block and filter abuse, while X has introduced a tool which displays the country or continent in which an account is based.

The BBC contacted both X and Meta with questions about abuse on their platforms. Neither provided a comment.

In an office in central London, Signify's small team quietly sifts through thousands of posts.

With every contentious moment during a game, the number of abusive messages rises.

Up pop posts containing monkey emoijs and racist slurs, threats of rape to the family members of managers, and even death threats, sparked purely by actions on a football pitch.

Every message the AI system deems abusive is checked twice by humans, who only count the messages which break social media platforms' own guidelines as verified abuse.

The most significant surge in abusive posts occurred during Tottenham's dramatic 2-2 draw with Manchester United on 8 November, a match that featured two stoppage-time goals, after which both clubs' managers and several players faced concentrated abuse.

In messages seen by the BBC, death threats were sent about Amorim, including one saying 'Kill Amorim - someone get that dirty Portuguese'.

The Online Safety Act, which came into force in October 2023, puts a statutory duty of care on social media platforms.

That means they are legally obliged to proactively identify and remove illegal content such as threats, harassment or hate speech. Ofcom is now the independent regulator responsible for making sure platforms comply.

But the social platforms argue that the right to free speech makes them reluctant to censor or remove content. 

Signify insists that the problem of serious abuse and threats sent online is worsening.

"We've seen around a 25% year-on-year increase in the levels of abuse we're detecting," said its chief executive Jonathan Hirshler.

"We understand the platforms' position on free speech but some of the stuff we're talking about is so egregious.

"Really nasty death threats and really horrible, violent content. If the people who are the free speech absolutists out there read some of those messages, they wouldn't question why some of these are being reported and why action needs to be taken."

This video can not be played

'25% year-on-year increase' - Can football clubs stop online abuse?

Controversy during Chelsea's 1-1 draw at Arsenal on 8 November sparked the vast majority of the 97 verified abusive messages posted about WSL matches.

More than half targeted Chelsea boss Bompastor, including a threat of violence and a homophobic slur.

"People think they can say anything they want from behind a screen," Bompastor said. "It's scary - I want to raise my voice against that.

"I have a family, including kids. They don't want to see those comments online. They are so young, and people need to realise the effect it can have on them too.

"Threats are a big problem, because the security in the women's game isn't the same as the men's game.

"Abuse can cause real mental problems for players. It can go really far."

Ex-Chelsea and current England defender Jess Carter was the subject of prominent racist abuse online during Euro 2025, and Bompastor believes the platforms themselves bear plenty of blame.

"The social media companies are not doing their job, not taking the responsibility or accountability," Bompastor said.

"If we have to wait for them to act, I think we will be in this situation for too long.

"I'm hoping now that all clubs in the women's and men's games are proactive and protect people as much as possible."

As frustration with social media companies grows, more clubs are taking matters into their own hands. 

Arsenal have worked with Signify for the past three years and have seen a 90% drop in the number of affiliated fans sending abuse to their own players, coach and owners. 

Signify attributes this to the fact that Arsenal have been actively taking action, including implementing education programmes and banning fans from the Emirates who have been identified as senders of abuse.

Chelsea women are now also working with the same company.

Tottenham, meanwhile, are conducting investigations into season-ticket holders alleged to have posted abusive content.

Premier League director of content protection Tim Cooper said: "We're constantly monitoring around matches where the abuse can happen and looking for trigger instances such as a goal being scored, missed penalties, or even things like yellow and red cards.

"The platforms can do more by changing their algorithms. That would be a step in the right direction."

If you have been affected by any of the issues raised in this story you can visit BBC Action Line.

