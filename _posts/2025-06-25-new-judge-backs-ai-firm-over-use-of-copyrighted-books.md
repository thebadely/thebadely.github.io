---
layout: post
title: "New: Judge backs AI firm over use of copyrighted books"
date: 2025-06-25T09:55:59
author: "badely"
categories: [Technology]
tags: []
excerpt: "A US court has ruled Anthropic was not breaching copyright rules when it trained its AI model on books."
image: assets/images/3f4cb70c97e719242a11f7ebb9d6555e.jpg
---

Here’s what you need to know: A US judge has ruled that using books to train artificial intelligence (AI) software is not a violation of US copyright law.

The decision came out of a lawsuit brought last year against AI firm Anthropic by  three authors, including best-selling mystery thriller writer Andrea Bartz, who accused it of stealing her work to train its Claude AI model and build a multi-billion dollar business. 

In his ruling, Judge William Alsup said Anthropic's use of the authors' books was "exceedingly transformative" and therefore allowed under US law.

But he rejected Anthropic's request to dismiss the case, ruling the firm would have to stand trial over its use of pirated copies to build its library of material.

Bringing the lawsuit alongside Ms Bartz, whose novels include We Were Never Here and The Last Ferry Out, were non-fiction writers Charles Graeber, author of The Good Nurse: A True Story of Medicine, Madness and Murder and Kirk Wallace Johnson who wrote The Feather Thief.

Anthropic, a firm backed by Amazon and Google's parent company, Alphabet, could face up to $150,000 in damages per copyrighted work.

The firm holds more than seven million pirated books in a "central library" according to the judge.

The ruling is among the first to weigh in on a question that is the subject of numerous legal battles across the industry - how Large Language Models (LLMs) can legitimately learn from existing material.

"Like any reader aspiring to be a writer, Anthropic's LLMs trained upon works, not to race ahead and replicate or supplant them — but to turn a hard corner and create something different," Judge Alsup wrote.

"If this training process reasonably required making copies within the LLM or otherwise, those copies were engaged in a transformative use," he said.

He noted that the authors did not claim that the training led to "infringing knockoffs" with replicas of their works being generated for users of the Claude tool.

If they had, he wrote, "this would be a different case".

Similar legal battles have emerged over the AI industry's use of other media and content, from journalistic articles to music and video.

This month, Disney and Universal filed a lawsuit against AI image generator Midjourney, accusing it of piracy.

The BBC is also considering legal action over the unauthorised use of its content.

In response to the legal battles, some AI companies have responded by striking deals with creators of the original materials, or their publishers, to license material for use.

Judge Alsup allowed Anthropic's "fair use" defence, paving the way for future legal judgements.

However, he said Anthropic had violated the authors' rights by saving pirated copies of their books as part of a "central library of all the books in the world".

In a statement Anthropic said it was pleased by the judge's recognition that its use of the works was transformative, but disagreed with the decision to hold a trial about how some of the books were obtained and used. 

The company said it remained confident in its case, and was evaluating its options.

A lawyer for the authors declined to comment.

